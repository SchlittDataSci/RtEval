---
title: "Collabathon: Simulating line-list data"
author: Chad Milando, PhD*^[Boston University, School of Public Health, Department of Environmental Health, cmilando@bu.edu]; Laura White, PhD^[Boston University, School of Public Health, Department of Biostatistics]; Tenglong Li, PhD^[Boston University, School of Public Health, Department of Biostatistics]; Zhenwei Zhou, PhD^[Boston University, School of Public Health, Department of Biostatistics]
date: "2024-09-24"
output: html_document
runtime: shiny
---

```{=html}
<style type="text/css">
.main-container {
  max-width: 750px;
  margin-left: auto;
  margin-right: auto;
}
</style>
```

```{css, echo=FALSE}
.plotlysize {
  height: 220px;
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plotly)
library(purrr)
library(shiny)
library(splines)
library(tidyverse)
```

This R Markdown document walks through the steps of simulating estimates of time-dependent reproductive number, $R(t)$ that can be helpful for surveillance and intervention planning of infectious diseases.

To do this, we first walk through the process of simulating **line-list data**, which means you have a single row for each case, that has dates for: infection, symptom onset, positive test, and when this was reported to public health agencies.

Defining terms is helpful at the beginning. [Lehtinen et. al. (2021)](https://royalsocietypublishing.org/doi/10.1098/rsif.2020.0756) defines 
terms as following:

```{r pressure, echo=FALSE, fig.cap="Figure 1 from Lehtinen et. al. (2021)", out.width = '60%'}
knitr::include_graphics("img/Lehtinen_fig1.jpg")
```

* $G_{ij}$ is the generation time, the time between infection in i and infection in j
* $I_i$ is the incubation time, between infection and sympton onset
* $P_{ij}$ is the transimission time between symptom onset in i and infection in j
* $S_{ij}$ is the serial interval, the time between sympton onset in i and symptom onset in j

**NOTE:** Each of these is in reference to the **infector**, so the **infector** ($i$) has a serial interval and a generation interval that is applied to each **infectee** ($j$). This is very important and comes up later.

So for this simulation, we take several steps to simulated how cases spread from one person to another. 

1. Simulate the individual-level incubation time distribution, then 
2. simulate the individual-level transmission time distribution. 

We then can derive distributions for the generation time and serial interval using the relationships described in [Lehtinen et. al. (2021)](https://royalsocietypublishing.org/doi/10.1098/rsif.2020.0756). 

We then:

3. simulate the individual-level administrative delay in reporting and 
4. simulate the population-level infectivity dynamics 

The result is simulated individual line-list and aggregated count data. 

For reproducibility, we fix the random seed.

```{r seed_set, echo = F}
inputPanel(shiny::helpText("set.seed(123)"))
set.seed(123)
```

We parameterized all distributions (except offspring, which were Poisson for now) using a right-truncated Negative Binomial (NB) distribution. NB dispersion (also called 'size') is a measure of over-dispersion (smaller size means more over-dispersion, which means variance != mean). For more information see [Zeileis](https://edoc.unibas.ch/15400/)

### Incubation time distribution
Incubation time between **infection** and **symptom onset** for an individual. We used a minimum incubation time (1 day) and a maximum incubation time (user defined). Incubation of exactly 1 day can be achieved by setting NB dispersion = 1e-10.

```{r inc_interval, echo=FALSE}
INC_MIN = 1

## INPUTS
inputPanel(
  # row 1
  sliderInput("inc_i_mean", label = "NB mean (days)", value = 2, min = 1, max = 15),
  sliderInput("inc_i_size", label = "NB dispersion", pre = '1e', value = 2, min = -10, max = 10),
  sliderInput("maxinc", label = "Max. incubation time (days)", value = 11,
              min = 5, max = 15, step = 1)
)

inc_data <- reactive({
  data.frame(x = sample(0:input$maxinc, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN ) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n)) 
})

inc_max <- reactive({ max(as_tibble(inc_data())$n) })

renderPlot({
    as_tibble(inc_data()) %>%
    ggplot(.,aes(x = x, y = n)) +
      geom_col(fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(inc_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```

### Transmission time distribution
Transmission time between **symptom onset** in **infector** and **infection** in **infectee** for an individual.  We parameterized using a right-truncated Negative Binomial (NB) distribution defined by a minimum transmission time (0 days) and a maximum transmission time (user defined). Transmission of exactly 0 days can be achieved by setting NB mean = 0, or NB dispersion = 1e-10.

```{r trans_interval, echo=FALSE}
TRANS_MIN = 0

## INPUTS
inputPanel(
  # row 1
  sliderInput("trans_i_mean", label = "NB mean (days)", value = 1, min = 0, max = 15),
  sliderInput("trans_i_size", label = "NB dispersion", pre = '1e', value = 2, min = -10, max = 20),
  sliderInput("maxtrans", label = "Max. transmission time (days)", value = 10,
              min = 5, max = 15, step = 1),
)

trans_data <- reactive({
      data.frame(x = sample(0:input$maxtrans, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN ) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n)) 
})

trans_max <- reactive({ max(as_tibble(trans_data())$n) })

renderPlot({
    as_tibble(trans_data()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(trans_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```


### Derived Generation time distribution
Generation time is the time between **infection** in the **infector** and **infection** in the **infectee**, dervied as $G_{ij} = I_{i} + P_{ij}$ (Eq. 2.1b from [Lehtinen et. al. (2021)](https://royalsocietypublishing.org/doi/10.1098/rsif.2020.0756)).

```{r gen_interval, echo=FALSE}

gen_data <- reactive({
      data.frame(x1 = sample(0:input$maxinc, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN,
               x2 = sample(0:input$maxtrans, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN)     %>%
    mutate(x = x1 + x2) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n)) 
})

gen_max <- reactive({ max(as_tibble(gen_data())$n) })

renderPlot({
    as_tibble(gen_data()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(gen_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```


### Derived Serial interval distribution
The serial interval can derived from the generation time distribution and the incubation time distribution: $S_{ij} = P_{ij} + I_j$ (Eq. 2.1a from [Lehtinen et. al. (2021)](https://royalsocietypublishing.org/doi/10.1098/rsif.2020.0756)).

```{r serial_interval, echo=FALSE}

serial_data <- reactive({
      data.frame(x1 = sample(0:input$maxinc, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN,
               x2 = sample(0:input$maxtrans, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN)     %>%
    mutate(x = x1 + x2) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n))
})

serial_max <- reactive({ max(as_tibble(serial_data())$n) })

renderPlot({
    as_tibble(serial_data()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(serial_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```


### Reporting delay distribution
Finally, we modeled a reporting delay distribution -- this is the time between **sympotom onset** and **case reporting** to a municipal agency. For this, we parameterized using a the truncated Negative Binomial (NB) distribution that defines the maximum reporting delay distribution. Perfect (i.e., instantaneous) reporting can be modeled with NB mean of 0. 

```{r, echo=FALSE}
## INPUTS
inputPanel(
  # row 1
  sliderInput("NB_m", label = "NB mean (days)", value = 0, min = 0., max = 20),
  sliderInput("NB_r", label = "NB dispersion", pre = '1e', value = 2, min = -1, max = 20),
  sliderInput("maxdelay", label = "Max. reporting delay (days)", value = 11,
              min = 10, max = 15, step = 1),
)

reporting_dist <- reactive({
      data.frame(x = sample(0:input$maxdelay, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxdelay, 
                                         size = 1*10^input$NB_r, 
                                         mu = input$NB_m), 
                          replace = TRUE) ) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n))
})

reporting_max <- reactive({ max(as_tibble(reporting_dist())$n) })

renderPlot({
    as_tibble(reporting_dist()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(reporting_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```
### R(t) simulation

Then describe the daily infections, onsets, and reporting days of first generation (the first round of infectees that you have data on -- you could think about this like people that were exposed at a conference out of state, that then traveled home and are now reporting in their home state). Assuming you have 100 initial cases (infectors), and distributions above.

**NOTE:** We are modeling Onset time as synonymous with infectivity, although this may not be true for many diseases. We also assume that the simulation **STARTS on DAY=0**. So the earliest infections will happen on Day 0, and the earliest onsets will happen on Day 1. 

```{r get_curves2, echo=FALSE}
n0  = 1000

plot_dat <- reactive({
  # ----------
  # one draw from poisson given by lambda = initial cases * initial reproductive number
  # this gives the first timestep of infectees from the initial cases
  # n1 <- rpois(1, n0 * input$r0) 
  
  # so first is the date of infection, 
  # which is a draw from the transmission distribution
  # NOTE: WHY
  i1 = sample(0:input$maxtrans, 
                        size = n0, 
                        prob = dnbinom(0:input$maxtrans, 
                                       size = 1*10^input$trans_i_size, 
                                       mu = input$trans_i_mean), 
                        replace = TRUE) + TRANS_MIN
  

  # next is onset times, which is transmission + incubation
  o1 = sample(0:input$maxinc, 
                          size = n0, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN
  o1 = o1 + i1

  # Finally, reporting, which is transmission + incubation + reporting delay
  d1 = sample(0:input$maxdelay, 
                          size = n0, 
                          prob = dnbinom(0:input$maxdelay, 
                                         size = 1*10^input$NB_r, 
                                         mu = input$NB_m), 
                          replace = TRUE)
  d1 <- o1 + d1

  # in addition, make a new draw for the generation interval with the 
  # reference person as the infectee
  # so this it the generation interval for EVERY J that EACH I infects.
  ## which is o1 + a new transmission draw for the next person
  ## this just gets the distribution of dates and then the r(t) is applied 
  ## to the sum to scale up the counts
  gi1 <- data.frame(x1 = o1,
               x2 = sample(0:input$maxtrans, 
                          size = n0, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN) %>%
    mutate(x = x1 + x2)
  
  # right and these all happen AFTER onset
  gi1 <- unname(gi1$x)
  
  # add generation #
  gen_i <- 1
  gen_i_c <- rep(gen_i, length(i1))
  
  # create a combined dataset
  dat <- cbind(i1, o1, d1, gi1, gen_i_c)
  
  dat
})
# 
# # Curves
# # area under the curve should be = 196
renderPlot({
  as_tibble(plot_dat()) %>%
    select(-gi1) %>%
    rename("Daily Infections" = i1,
           "Daily Onsets" = o1,
           "Daily Reports" = d1) %>%
    pivot_longer(cols = c("Daily Infections", "Daily Onsets",
                          "Daily Reports")) %>%
    group_by(name, gen_i_c, value) %>% tally() %>%
    ggplot(.) +
    geom_bar(aes(x = value, fill = factor(gen_i_c), y = n),
             position = 'stack', stat = 'identity', color = 'black',
             lwd = 0.1, fill = '#6495ED') +
    facet_wrap(~name, nrow = 1) +
    ylab('N') + xlab('Day') +
    scale_fill_brewer(name = 'Gen.#', type = 'seq',
                      direction = 1, palette = 3) +
    theme_gray() + 
    #coord_cartesian(xlim = c(0, 30), ylim = c(0, 50)) +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14),
          strip.text = element_text(size = 14)
    ) 
}, height = 200)
```

Now, create your $R(t)$ curve so you can simulate the next generation(s) of cases (**starting at $t=1$**), . Pre-defining the shape of $R(t)$ allows you to simulate infectious disease dynamics, interventions, etc. The dotted line at $R(t)=1$ shows the span of $R(t)$, from $t=[1, T]$. if $R(t) > 1$ for all $t$, the cases will expontentially increase, and the code will not complete for modeling windows greater than 30 days. You can change the code to have a different spline between points. 


```{r bsdeg, echo=FALSE}

inputPanel(
  # sliderInput("r0", label = "R(t = 0):",
  #             min = 0.2, max = 2, value = 1.6, step = 0.1),
  sliderInput("RTINF", label = "Final R(t):",
              min = 0.2, max = 2, value = 1, step = 0.1),
  sliderInput("ld", label = "Modeling window (days)", value = 35,
              min = 30, max = 60, step = 5),
  sliderInput('BSDEG', 'Spline Degree:', value = 1, min = 1, max = 4, step = 1)
)

```

<div class = 'plotlysize'>
```{r set_rt, echo=FALSE}
# PLOT PARAMETERS
YMAX <- 2
NPTS <- 8
XSTART <- 1

# REFERENCE: # https://stackoverflow.com/questions/47280032/draggable-line-chart-in-r-shiny
### asb should be '30'
rv <- reactiveValues(
  x = NULL,
  #y = rep(1, length.out = NPTS)
  y = c(1.1, 1.5, 1.1, 0.5, 1, 1.5, 1, 1)
)

## these are the spline knots
observeEvent(input$ld, {
  rv$x <- seq(XSTART, input$ld, length.out = NPTS)
  #rv$y <- rep(1, times = NPTS)
})

## make sure that the output are on the day
## so this is a two-step process. first you make the linear data
## then you predict the spline based on BSDEG
rt_grid <- reactive({
  this.x <- seq(XSTART, input$ld, by = 1)
  suppressWarnings(this.y <- predict(linear.model(), data.frame(x = this.x)))
  linear_data = data.frame(x = this.x, y = this.y)
  X_mat <- bs(x = this.x, knots = rv$x, degree = input$BSDEG)
  m2 <- lm(this.y ~ X_mat)
  yspline <- predict(m2)
  data.frame(x = this.x, y = as.vector(yspline))
})

linear.model <- reactive({
  d <- data.frame(x = rv$x, y = rv$y)
  lm(y ~ bs(x, degree = 1, knots = rv$x), d)
})

# Render plot
renderPlotly({
  
  req(rv$x)
  req(rv$y)
  req(rt_grid()$x)
  req(rt_grid()$y)
  
  # creates a list of circle shapes from x/y data
  circles <- map2(
    rv$x, rv$y,
    ~ list(
      type = "circle",
      # anchor circles
      xanchor = .x,
      yanchor = .y,
      # give each circle a 2 pixel diameter
      x0 = -4, x1 = 4,
      y0 = -4, y1 = 4,
      xsizemode = "pixel",
      ysizemode = "pixel",
      # other visual properties
      fillcolor = "red",
      ## hover info?
      ## stroke??
      line = list(color = "black", stroke = 5)
    )
  )

  # plot the shapes and fitted line
  p <- plot_ly(source = 'mysource', height=200) %>%
    add_lines(x = c(XSTART, input$ld), y = c(1, 1), color = I("black"),
              line = list(widthh=0.5, dash="dot"), showlegend = F) %>%
    add_lines(x = rt_grid()$x, y = rt_grid()$y, color = I("#F89880"),
              showlegend = F,
              hoverinfo = 'y',
              hovertemplate = paste("%{y:.3f}<extra></extra>")
              ) %>% 
    layout(
        plot_bgcolor = '#f0f0f0', # Light grey background
        # xaxis
        xaxis = list(
          title = "Day",
          zerolinecolor = "#f0f0f0", # Light grey zeroline color
          gridcolor = "#ffffff",     # White grid lines
          titlefont = list(family = "Arial, sans-serif"),
          tickfont = list(family = "Arial, sans-serif"),
          range = c(0.1, input$ld + 1)
          #tickvals = c(2),            # Custom tick at x = 2
          #ticktext = c("t=2")       # Custom label for x = 2
        ),
        # yaxis
        yaxis = list(
          title = "R(t)",
          range = c(0, YMAX),
          zerolinecolor = "#f0f0f0", # Light grey zeroline color
          gridcolor = "#ffffff",     # White grid lines
          titlefont = list(family = "Arial, sans-serif"),
          tickfont = list(family = "Arial, sans-serif")
        ),
        margin = list(l = 35, r = 0, b = 0, t = 0), # Adjusted margins
        shapes = circles,
        font = list(family = "Arial, sans-serif")
      ) %>%
      config(edits = list(shapePosition = TRUE)) 
    
    p
})

observe({
    warning("\n************\nCWM Note on 9.24.2024: I haven't figured out how to fix the `plotly` event register warning, it happens when it tries to register the `event_data()` before the plot has data. See this link: https://github.com/plotly/plotly.R/issues/1528\n************\n")
})

# update x/y reactive values in response to changes in shape anchors
observe({
  ed <- event_data("plotly_relayout", source = 'mysource')
  
  shape_anchors <- ed[grepl("^shapes.*anchor$", names(ed))]
  if (length(shape_anchors) != 2) {
    return()
  }
  row_index <- unique(readr::parse_number(names(shape_anchors)) + 1)
  pts <- as.numeric(shape_anchors)
  
  # some controls on the bounds
  if(row_index == 1) {
    rv$x[row_index] <- XSTART
  } else if (row_index == NPTS) {
    rv$x[row_index] <- input$ld
  } else {
    rv$x[row_index] <- sapply(pts[1], function(x) 
      ifelse(x < XSTART, XSTART, ifelse(x > input$ld, input$ld, x)))
  }
  
  rv$y[row_index] <- sapply(pts[2], function(y) 
    ifelse(y < 0, 0, ifelse(y > YMAX, YMAX, y)))
})

```
</div>

Now, create the all subsequent generations within the modeling window (generation # is indicated by fill color in the graph below, with lighter being later generations. The first generation is outlined in red). The Poisson offspring of each generation are based on the $R(t)$ value on given by the **GENERATION INTERVAL** of the previous generation -- so, if you get infected, but then there is a lockdown, the $R(t)$ value that determines how many people you infect will reflect that. 

**NOTE: ** The generation to generation offspring are modeled as a Poisson distribution: $n_{i+1} = Poisson(\lambda= n_{i} * R(i))$. This may be updated to a Negative Binomial distribution in future iterations

```{r echo=FALSE}
dat_all <- reactive({
  
  dat <- as_tibble(plot_dat())
  
  # this is the first generation
  i1 <- dat$i1   # infection date
  o1 <- dat$o1   # onset date
  gi1 <- dat$gi1 # generation interval
  gen_i <- 1

  # GET RT
  rt_y = rt_grid()$y
  rt_x = rt_grid()$x
  stopifnot(rt_x[1] == 1)
  stopifnot(rt_x[input$ld] == input$ld)
  # print(rt_grid()$x)
  # print(rt_y)
  
  # ----------
  # while there are any initial infection dates lower than the modeling window
  # end, simulate the next generation
  # while (gen_i < 2) {
  while(any(i1<=input$ld)) {
  
    ## new generation
    # print('************')
    gen_i <- gen_i + 1

    ## Infection or Onset dates of previous generation
    inf_date <- as.numeric(names(table(i1)))
    ons_date <- as.numeric(names(table(o1)))
    gi_date  <- as.numeric(names(table(gi1)))
    # print("infection date")
    # print(inf_date)
    # print("onset date")
    # print(ons_date)
    # print("si_date")
    # print(si_date)
    ### IF THERE IS A 0 you're screwed
    if(0 %in% gi_date) stop("0 in gi_date dates")

    ## Number of cases on each infection or onset date
    inf_no   <- as.numeric(table(i1))
    ons_no   <- as.numeric(table(o1))
    gi_no    <- as.numeric(table(gi1))
    stopifnot(sum(inf_no) == sum(ons_no))
    stopifnot(sum(inf_no) == sum(gi_no))
    # print("infection number")
    # print(inf_no)
    # print("onset number")
    # print(ons_no)
    # print("si number")
    # print(si_no)
    ## get the next iteration of rT using the file provided.
    ## repeat RTINF until the end of the sequence,
    ## in this case, the largest onset date
    MAX_DT = 100
    rt <- c(rt_y, rep(input$RTINF, times = max(MAX_DT))) 
    stopifnot(length(rt[gi_date]) == length(gi_no))
    
    ## then, get a vector of poisson variaables for the 
    ## mu of poisson offspring for the next generation
    ## rt_vec is for the specific dates identified in `date`
    ## if you want this to be based on onset you change this to onset_no
    ## so the onset_dates reflect the transmission and incubation from the previous generation
    ## aka the serial interval
    ## NOW HERE IS THE REAL REAL QUESTION, SHOULD THE RT BE BASED ON THE DATE OF
    ## INFECTION OR THE DATE OF GENERATION
    ## PROBABLY THE DATE OF GENERATION BUT A GOOD QUESTION
    mu   <- gi_no * rt[gi_date]
    # print('mu poisson')
    # print(mu)
    
    # so this gives the expected value of NEW CASES ON SPECIFIC DAYS GIVEN 
    # the current pool of infectees (ons_no) on those days (ons_date)
    
    ## simulate the next generation of infectees
    ## so on the date of symptom onset for current infectees
    # this is the number of people that will be infected
    n1   <- sapply(mu, function(mx) rpois(1, mx))
    # print('next gen')
    # print(n1)
    # print(sum(n1))

    ## and their infection dates, determined by the onset in i + transmission time
    # include the start dates before the generation time
    # if you change to infection date, you have include the onset time 
    # from the previous generation, because you don't get infected until onset
    
    # Update, no, this is actually determined from the GI of the previous generation
    next_gen_i_days <- do.call(c, lapply(1:length(n1), function(i) {
      rep(gi_date[i], times = n1[i]) }))
    # print(next_gen_i_days)

    # trans1 <- sample(0:input$maxtrans, 
    #                     size = sum(n1), 
    #                     prob = dnbinom(0:input$maxtrans, 
    #                                    size = 1*10^input$trans_i_size, 
    #                                    mu = input$trans_i_mean), 
    #                     replace = TRUE) + TRANS_MIN
    # 
    # stopifnot(length(onset_days) == length(trans1))
    
    i1   <- next_gen_i_days
    
    ## and thier onset times, which is infection + incubation
    inc1 <- sample(0:input$maxinc, 
                          size = sum(n1), 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN
      
    o1   <- i1 + inc1
    
    ## and then just tack on the Date of report
    d1   <- o1 + sample(0:input$maxdelay, 
                          size = sum(n1), 
                          prob = dnbinom(0:input$maxdelay, 
                                         size = 1*10^input$NB_r, 
                                         mu = input$NB_m), 
                          replace = TRUE)
    
    ## And now the generation interval for every subsequent generation produced by 
    ## this set of infectors
    ## this is o1 + a new transmission draw
    gi1 <- data.frame(x1 = o1,
             x2 = sample(0:input$maxtrans, 
                        size = sum(n1), 
                        prob = dnbinom(0:input$maxtrans, 
                                       size = 1*10^input$trans_i_size, 
                                       mu = input$trans_i_mean), 
                        replace = TRUE) + TRANS_MIN) %>% mutate(x = x1 + x2)
    gi1 <- unname(gi1$x)
    
    ##
    gen_i_c <- rep(gen_i, length(i1))
    
    dat1 <- cbind(i1, o1, d1, gi1, gen_i_c)
    ###
    dat  <- rbind(dat, dat1)
  }

  dat
  
})

# get aggregated data
# NAs have to be preserved or else
aggDat <- reactive({
  
  x <- as_tibble(dat_all())
  
  max_dt <- max(x$d1)
  
  x1 <- x %>%
    select(-gi1) %>% ## remove g1
    rename("Daily Infections" = i1, 
           "Daily Onsets" = o1, 
           "Daily Reports" = d1) %>%
    pivot_longer(cols = c("Daily Infections", "Daily Onsets", 
                          "Daily Reports")) %>%
    group_by(name, value) %>% tally() %>% 
      rename(day = value) %>%
      pivot_wider(id_cols = day, names_from = name,
                  values_from = n, values_fill = NA) ## MUST BE NA
  
  all_dt <- data.frame(day = 0:max_dt)
  
  x2 <- all_dt %>% left_join(x1, by = join_by(day))
  
  for(j in 2:ncol(x2)) x2[which(is.na(x2[, j])), j] <- NA ## MUST BE NA
  
  x2
  
})

# get all Rt values
allRt <- reactive({
  # print("***")
  rt_y = rt_grid()$y
  rinf = input$RTINF

  max_dt = max(dat_all()$i1)

  Rall = data.frame(x = 1:max_dt, y = NA)
  for(i in 1:nrow(Rall)) {
    if(i <= input$ld) {
      Rall$y[i] = rt_y[i]
    } else {
      Rall$y[i] = rinf
    }
  }
  
  # print(Rall)
  # print("***2")
  Rall
  
})

renderPlot({
  
  ## summary plot
  # Curves
  as_tibble(dat_all()) %>%
    select(-gi1) %>% ## remove g1
    rename("Daily Infections" = i1, 
           "Daily Onsets" = o1, 
           "Daily Reports" = d1) %>%
    pivot_longer(cols = c("Daily Infections", "Daily Onsets", 
                          "Daily Reports")) %>%
    group_by(name, gen_i_c, value) %>% tally() %>%
    mutate(is_gen_1 = gen_i_c == 1) %>%
    ggplot(.) +
    geom_bar(aes(x = value, fill = gen_i_c, y = n, 
                 color = is_gen_1, lwd = is_gen_1), 
             position = 'stack', stat = 'identity', width = 0.8) + 
    facet_wrap(~name, nrow = 1) + 
    ylab('N') + xlab('Day') +
    scale_fill_continuous(name = 'Gen. #') +
    scale_color_manual(name = "", values = c("transparent", "red")) +
    scale_linewidth_manual(name = "", values = c(0.1, 1)) +
    # scale_fill_brewer(name = 'Gen.#', type = 'seq', 
    #                   direction = -1, palette = 3) + 
    theme_gray() + 
    coord_cartesian(xlim = c(0, input$ld)) +
    theme(legend.position = 'none',
                axis.text = element_text(size = 10),
          axis.title = element_text(size = 14),
          strip.text = element_text(size = 14))
  
}, height = 200 )
```

### Calculating R(t) from aggregated data

Now, what is the "true" R(t) for infectivity that was calculated here? The R(t) value above is the expected value, but we'd have to predict many scenarios in order to sample and recover that. Instead, we want to calculate what the R(t) was in this specific realization of the expected value.

You can calculate it by inverting the renewal equation (i.e., $m(t) = \Sigma_{\tau < t} ~ R(t) ~ \omega(\tau) ~ m(t-\tau)$) to solve for $R(t)$. The black line below replicates the R(t) that is used as the expected value to create the data and the red line is are the draws from the Poisson and NB processes that are described above. The key to making this work was using the generation interval from the previous generation to define when the next generation's infection dates where, then using the R(t) values for those infection dates to determine the next round of offspring. 


**NOTE:** The beginning of the curve have some expected instability. The beginning because we are drawing randomly from a Poisson process that has no preceeding values to anchor it to. If there is any transmission distribution, these values become shifted, and thus the calculated R(t) based on the generation interval is much higher than it should be. You can see the impact of this effect by setting the transmission distribution to instantaenous. What this tells us is that when you have instant transmission, all of the day0 cases immediately have an impact as specified by the expected value of R(t) on that day. 

```{r}
get_Rt <- function(m, w) {

  R <- rep(NA, length(m))
  
  for(t in 2:length(m)) {
    tau_end = min(length(w), t - 1)
    c_mat <- w[1:tau_end] %*% m[t - 1:tau_end]
    R[t] <- m[t] / c_mat
  }
  
  return(R)
}
```


```{r echo=FALSE}
renderPlot({
    
    ## first, get cases
    m = aggDat()$`Daily Infections`
    m[is.na(m)] <- 0
    
    # print("**w")
    ## using generation data, because its infections
    ## but will be thes ame as serial_interval
    w = as_tibble(gen_data())$n

    # print(w)
    calc_rt = get_Rt(m, w)
    calc_rt_df <- data.frame(rt = calc_rt)
    calc_rt_df$x = aggDat()$day

    calc_rt_df <- calc_rt_df %>%
     filter(!is.na(rt), x <= input$ld)
    
    ###
    my_rescale <- function(x, a, b) {
      new_length = b - a
      scale_factor = 1.0
      scaled_p = x / scale_factor
      new_length * scaled_p + a
    }

    sx = -0.6
    
    second_axis <- data.frame(
      xmin = c(sx),
      xmax = c(sx),
      ymin = c(0.0),
      ymax = c(0.5)
    )
    
    plotlab <- data.frame(
      x = -0.2 + 0.1,
      y = 0.6,
      lab = 'Transmission P(x)'
    )

    second_axis_ticks <- data.frame(
      xmin = c(second_axis$xmin-0.1, second_axis$xmin-.1, second_axis$xmin-.1, second_axis$xmin-.1, second_axis$xmin-.1),
      xmax = c(second_axis$xmax, second_axis$xmax, second_axis$xmax, second_axis$xmax, second_axis$xmax),
      ymin = my_rescale(c(0, 0.25, 0.5, 0.75, 1), 0.0, 0.5),
      ymax = my_rescale(c(0, 0.25, 0.5, 0.75, 1), 0.0, 0.5),
      lab = c("", "0.25", '', '0.75', "")
    )
    
    ####
    ggplot( as_tibble(allRt()) %>% 
              filter(!is.na(y), x <= input$ld), aes(x = x, y = y) ) +
    geom_line() + 
      geom_point() +
    # *****
    geom_path(data = calc_rt_df, aes(x = x , y = rt), color = 'red') +
    geom_point(data = calc_rt_df, aes(x = x , y = rt), color = 'red') +
    # *****
    xlab('Day') + ylab('R(t)') +
    # geom_vline(xintercept = input$ld, color = 'purple', linetype = 'dashed') +
    geom_col(data = as_tibble(trans_data()), 
                 aes(x = x, y = my_rescale(n, 0, 0.5)),
              stat = 'identity', fill = '#FF6666', alpha = 0.5) +
    coord_cartesian(ylim = c(0, 2)) +
        geom_text(data = plotlab, aes(x = x, y = y, label = lab), size = 3,
            family = 'Helvetica') +
    ##
    geom_segment(data = second_axis, aes(x = xmin, xend = xmax, 
                                   y = ymin, yend = ymax), linewidth = 0.4) +
    geom_segment(data = second_axis_ticks, aes(x = xmin, xend = xmax, 
                                               y = ymin, yend = ymax), 
                 linewidth = 0.2) +
    geom_text(data = second_axis_ticks, aes(x = xmin - 0.4,  
                                            y = ymin, label = lab), size = 2,
              family = 'Helvetica') +
    
    theme(
      axis.text = element_text(size = 10),
      axis.title = element_text(size = 14))
  
  
}, height = 200 )

```

In theory, all R(t) packages should predict the red line (a single realization of the expected value), as the black line is not easily recoverable without multiple simulations to defined the expected value. This will depend on the extend to which the packages take into account onset and reporting delays (if these are included). So if you are using a package that doesn't take into account reporting delays, use a simulation with no reporting delay.

### Download data

Now can now download **line-list** data for every person within the modeling window, or **aggregated** infections, onsets, and reports by day. \

```{r, echo = FALSE}
inputPanel(
  downloadButton("downloadData", "LineList data"),
  downloadButton("downloadAggData", "Aggregated data")
)

output$downloadData <- downloadHandler(
    filename = function() {
        paste("linelist_data", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(  as_tibble(dat_all()) %>%
    rename("day_of_infection" = i1, 
           "day_of_onset" = o1, 
           "day_of_report" = d1) %>%
      select(-gen_i_c) %>%
      mutate(person_id = row_number()) %>%
      select(person_id, day_of_infection,
             day_of_onset, day_of_report), file, row.names = F)
    }
)

output$downloadAggData <- downloadHandler(
    filename = function() {
        paste("aggregated_data", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(  as_tibble(aggDat()), file, row.names = F)
    }
)

```

<br />
You can also download distributions data. 

```{r, echo = FALSE}
inputPanel(
    downloadButton("dist_serial", "Serial interval"),
    downloadButton("dist_gen", "Generation time"),
    downloadButton("dist_inc", "Incubation time "),
    br(), br(), br(),
    downloadButton("dist_trans", "Transmission time"),
    downloadButton("reporting_dist", "Reporting delay"),
    downloadButton("dist_rt", "Rt")
)

##
output$dist_serial <- downloadHandler(
    filename = function() {
        paste("dist_serial", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(serial_data()) %>%
                    rename(Day = x,
                           "P(x)" = n), file, row.names = F)
    }
)

##
output$dist_gen <- downloadHandler(
    filename = function() {
        paste("dist_gen", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(gen_data())%>%
                    rename(Day = x,
                           "P(x)" = n), file, row.names = F)
    }
)

##
output$dist_inc <- downloadHandler(
    filename = function() {
        paste("dist_inc", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(inc_data())%>%
                    rename(Day = x,
                           "P(x)" = n), file, row.names = F)
    }
)

output$dist_trans <- downloadHandler(
    filename = function() {
        paste("dist_trans", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(trans_data())%>%
                    rename(Day = x,
                           "P(x)" = n), file, row.names = F)
    }
)

output$reporting_dist <- downloadHandler(
    filename = function() {
        paste("reporting_dist", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(reporting_dist())%>%
                    rename(Day = x,
                           "P(x)" = n), file, row.names = F)
    }
)

output$dist_rt <- downloadHandler(
    filename = function() {
        paste("dist_rt", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(allRt() %>% rename(Day = x,
                           "R(t)" = y)) %>%
                    rbind(), file, row.names = F)
    }
)

```

\
You can also download an RDS of all data. \

```{r, echo = FALSE, out.width='100%'}
inputPanel(
    downloadButton("all_rds", "Save RDS")
)

##
output$all_rds <- downloadHandler(
    filename = function() {
        paste0('all_data.RDS')
    },
    
    content = function(file) {
        saveRDS(object = list(
          'incubation' = as_tibble(inc_data())%>%rename(Day = x,"Px" = n),
          'generation' = as_tibble(gen_data())%>%rename(Day = x,"Px" = n),
          'transmission' = as_tibble(trans_data())%>%rename(Day = x,"Px" = n),
          'serial' = as_tibble(serial_data())%>%rename(Day = x,"Px" = n),
          'reporting_delay' = as_tibble(reporting_dist())%>%rename(Day = x,"Px" = n),
          'rt' = as_tibble(allRt()) %>% rename(Day = x,"Rt" = y),
          'cases' = as_tibble(aggDat())
        ), file = file)
    }
)

```


